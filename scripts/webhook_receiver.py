# -*- coding: utf-8 -*-
"""webhook_receiver.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19IkrqwUpaH_3W88cMBpTsb2eb8zSq5Za
"""

#!/usr/bin/env python3
"""
webhook_receiver.py

A robust Flask webhook receiver that accepts many types of incoming payloads
and gracefully handles unusual/malformed arguments. It downloads or extracts
CSV files (or other tabular data) and saves them into `data/incoming/`, then
triggers the ingestion pipeline asynchronously.

Features:
- Endpoints: POST /ingest, POST /notify, GET /health
- Accepts JSON bodies, form-data file uploads, direct file_url fields,
  nested JSON with URLs, and base64-encoded file contents in any field.
- Supports local testing with file:// paths (e.g. file:///mnt/data/Untitled25.ipynb)
- Simple API-key authentication via X-API-KEY header or ?api_key=... query
- Saves incoming files to data/incoming/ and returns which files were saved
- Triggers scripts/ingest_and_prepare.py in a background thread
- Defensive: never trusts external input; validates CSV-like content before saving

Usage (development):
    pip install flask requests python-dotenv
    export WEBHOOK_SECRET=replace-me
    python scripts/webhook_receiver.py

Example test (local file copy):
    curl -X POST http://127.0.0.1:5000/ingest -H "Content-Type: application/json" \
      -H "X-API-KEY: replace-me" \
      -d '{"file_url":"file:///mnt/data/Untitled25.ipynb"}'

(Above path is the example file you uploaded; in production you will use CSV file URLs.)
"""

import base64
import os
import re
import shutil
import subprocess
import sys
import threading
import time
from datetime import datetime
from typing import Any, Dict, List, Tuple

from flask import Flask, request, jsonify
import requests
from dotenv import load_dotenv

# Load environment variables from config/secrets.env if present
ENV_PATH = os.path.join(os.path.dirname(__file__), "..", "config", "secrets.env")
if os.path.exists(ENV_PATH):
    load_dotenv(ENV_PATH)
else:
    # Also allow .env in project root
    load_dotenv(os.path.join(os.path.dirname(__file__), "..", ".env"))

WEBHOOK_SECRET = os.getenv("WEBHOOK_SECRET", os.getenv("API_KEY", "replace-me"))
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
INCOMING_DIR = os.path.join(PROJECT_ROOT, "data", "incoming")
INGEST_SCRIPT = os.path.join(PROJECT_ROOT, "scripts", "ingest_and_prepare.py")

os.makedirs(INCOMING_DIR, exist_ok=True)

app = Flask(__name__)

# ---------- Helpers ----------

def authorized(req) -> bool:
    """Check header X-API-KEY or query param api_key"""
    key = req.headers.get("X-API-KEY") or req.args.get("api_key")
    if not key:
        return False
    return key == WEBHOOK_SECRET


def safe_filename(filename: str) -> str:
    """Create a safe filename to store in incoming dir."""
    name = os.path.basename(filename)
    # remove dangerous chars
    name = re.sub(r"[^a-zA-Z0-9._-]", "_", name)
    ts = datetime.utcnow().strftime("%Y%m%dT%H%M%S")
    return f"{ts}_{name}"


def is_likely_csv_bytes(b: bytes) -> bool:
    """Heuristic to check if bytes look like CSV/text table content."""
    try:
        s = b.decode("utf-8", errors="ignore")
    except Exception:
        return False
    # if it contains many commas/newlines and printable chars -> likely CSV
    if s.count("\n") < 1:
        return False
    # presence of commas or tabs on multiple lines
    lines = s.splitlines()[:10]
    comma_lines = sum(1 for L in lines if "," in L)
    tab_lines = sum(1 for L in lines if "\t" in L)
    if comma_lines + tab_lines >= 1:
        return True
    # fallback: contains headers-like words
    if re.search(r"year|governorate|nationalit|students|teachers|occupation", s, re.I):
        return True
    return False


def save_bytes_to_incoming(b: bytes, suggested_name: str) -> str:
    fname = safe_filename(suggested_name)
    dst = os.path.join(INCOMING_DIR, fname)
    with open(dst, "wb") as fh:
        fh.write(b)
    return dst


def download_url(url: str, headers: Dict[str, str] = None, timeout: int = 60) -> Tuple[str, str]:
    """Download an http(s) or file:// URL to incoming dir. Returns (saved_path, error).
    Supports local file:// copying for testing.
    """
    headers = headers or {}
    if url.startswith("file://"):
        local = url[7:]
        if not os.path.exists(local):
            return ("", f"Local path not found: {local}")
        # copy local file content
        try:
            dst = os.path.join(INCOMING_DIR, safe_filename(local))
            shutil.copy2(local, dst)
            return (dst, "")
        except Exception as e:
            return ("", str(e))

    try:
        r = requests.get(url, headers=headers, timeout=timeout, stream=True)
        r.raise_for_status()
        # determine suggested filename
        cd = r.headers.get("content-disposition")
        if cd and "filename=" in cd:
            suggested = cd.split("filename=")[-1].strip().strip('"')
        else:
            suggested = os.path.basename(url.split("?")[0]) or "download.csv"
        # read small portion to validate
        content = r.content
        if not is_likely_csv_bytes(content):
            # still save it but mark as maybe-not-csv
            dst = save_bytes_to_incoming(content, suggested)
            return (dst, "warning:not_csv_content")
        dst = save_bytes_to_incoming(content, suggested)
        return (dst, "")
    except Exception as e:
        return ("", str(e))


def extract_candidates(obj: Any) -> List[Tuple[str, Any]]:
    """Walk any JSON-like object and find fields that might represent files:
    - values that are URLs (http/https/file)
    - values that are long base64 strings
    - values that look like CSV text

    Returns list of tuples (type, value) where type in ('url','base64','text').
    """
    candidates = []

    def walk(x):
        if isinstance(x, dict):
            for k, v in x.items():
                # check key names that often hold file info
                if k.lower() in ("file_url", "file", "url", "download", "path", "data") and isinstance(v, str):
                    if v.startswith("http://") or v.startswith("https://") or v.startswith("file://"):
                        candidates.append(("url", v))
                        continue
                walk(v)
        elif isinstance(x, list):
            for item in x:
                walk(item)
        elif isinstance(x, str):
            s = x.strip()
            # url
            if s.startswith("http://") or s.startswith("https://") or s.startswith("file://"):
                candidates.append(("url", s))
                return
            # base64 detection (very loose)
            if len(s) > 200 and re.fullmatch(r"[A-Za-z0-9+/=\n\r]+", s.replace("\n", "")):
                candidates.append(("base64", s))
                return
            # raw CSV-ish text: has newlines and commas
            if "\n" in s and ("," in s or "\t" in s):
                candidates.append(("text", s))
                return

    walk(obj)
    return candidates


def trigger_ingest_async():
    def _worker():
        try:
            subprocess.run([sys.executable, INGEST_SCRIPT, "--run"], check=True)
        except Exception as e:
            app.logger.error("Ingest failed: %s", e)

    t = threading.Thread(target=_worker, daemon=True)
    t.start()


# ---------- Flask endpoints ----------

@app.route("/health", methods=["GET"])
def health():
    return jsonify({"status": "ok", "incoming_dir": INCOMING_DIR})


@app.route("/ingest", methods=["POST"])
def ingest_endpoint():
    # Basic auth check
    if not authorized(request):
        return jsonify({"error": "unauthorized"}), 401

    saved = []
    errors = []

    # 1) Check for multipart file uploads (form-data)
    if request.files:
        for name, file_storage in request.files.items():
            try:
                raw = file_storage.read()
                if not raw:
                    errors.append({"field": name, "error": "empty file"})
                    continue
                # suggest original filename
                suggested = getattr(file_storage, "filename", f"upload_{name}.csv")
                path = save_bytes_to_incoming(raw, suggested)
                saved.append({"source": f"form:{name}", "path": path})
            except Exception as e:
                errors.append({"field": name, "error": str(e)})

    # 2) If JSON body, try to extract file_url or embedded base64/text
    content_type = request.headers.get("Content-Type", "")
    if content_type.startswith("application/json") or content_type.startswith("text/"):
        payload = request.get_json(silent=True)
        if payload is None and request.data:
            # fallback: raw text
            payload = {"_raw_text": request.get_data(as_text=True)}
        if payload is not None:
            candidates = extract_candidates(payload)
            for ctype, val in candidates:
                if ctype == "url":
                    path, err = download_url(val)
                    if path:
                        saved.append({"source": val, "path": path})
                    else:
                        errors.append({"source": val, "error": err})
                elif ctype == "base64":
                    try:
                        b = base64.b64decode(val)
                        # validate
                        if not is_likely_csv_bytes(b):
                            # still save but mark
                            p = save_bytes_to_incoming(b, "embedded_base64.dat")
                            saved.append({"source": "embedded_base64", "path": p, "note": "maybe_not_csv"})
                        else:
                            p = save_bytes_to_incoming(b, "embedded.csv")
                            saved.append({"source": "embedded_base64", "path": p})
                    except Exception as e:
                        errors.append({"source": "embedded_base64", "error": str(e)})
                elif ctype == "text":
                    try:
                        b = val.encode("utf-8")
                        if not is_likely_csv_bytes(b):
                            p = save_bytes_to_incoming(b, "embedded_text.dat")
                            saved.append({"source": "embedded_text", "path": p, "note": "maybe_not_csv"})
                        else:
                            p = save_bytes_to_incoming(b, "embedded.csv")
                            saved.append({"source": "embedded_text", "path": p})
                    except Exception as e:
                        errors.append({"source": "embedded_text", "error": str(e)})

    # 3) Check form fields or query parameters for file_url or data
    # Accept unusual argument names by scanning all values
    # form and args values
    all_values = []
    try:
        for k, v in dict(request.form).items():
            all_values.append((k, v))
    except Exception:
        pass
    for k, v in dict(request.args).items():
        all_values.append((k, v))

    for k, v in all_values:
        if isinstance(v, list):
            v = v[0]
        if not isinstance(v, str):
            continue
        s = v.strip()
        if s.startswith("http://") or s.startswith("https://") or s.startswith("file://"):
            path, err = download_url(s)
            if path:
                saved.append({"source": f"param:{k}", "path": path})
            else:
                errors.append({"source": f"param:{k}", "error": err})
        # check if value looks like base64 or CSV text
        if len(s) > 200 and re.fullmatch(r"[A-Za-z0-9+/=\n\r]+", s.replace("\n", "")):
            try:
                b = base64.b64decode(s)
                p = save_bytes_to_incoming(b, f"param_{k}.bin")
                saved.append({"source": f"param_base64:{k}", "path": p})
            except Exception as e:
                errors.append({"source": f"param_base64:{k}", "error": str(e)})

    # 4) If we saved any file, trigger ingest asynchronously
    if saved:
        trigger_ingest_async()

    return jsonify({"saved": saved, "errors": errors})


@app.route("/notify", methods=["POST"])
def notify_endpoint():
    # Accepts arbitrary JSON payloads and tries to find URLs inside
    if not authorized(request):
        return jsonify({"error": "unauthorized"}), 401
    payload = request.get_json(silent=True)
    if payload is None:
        return jsonify({"error": "invalid json or empty payload"}), 400
    candidates = extract_candidates(payload)
    saved = []
    errors = []
    for ctype, val in candidates:
        if ctype == "url":
            p, err = download_url(val)
            if p:
                saved.append({"source": val, "path": p})
            else:
                errors.append({"source": val, "error": err})
    if saved:
        trigger_ingest_async()
    return jsonify({"saved": saved, "errors": errors, "found_candidates": candidates})


# Simple admin/list endpoint to show recent incoming files
@app.route("/admin/list", methods=["GET"])
def admin_list():
    if not authorized(request):
        return jsonify({"error": "unauthorized"}), 401
    files = []
    for name in sorted(os.listdir(INCOMING_DIR), reverse=True)[:200]:
        p = os.path.join(INCOMING_DIR, name)
        try:
            stat = os.stat(p)
            files.append({"name": name, "path": p, "size": stat.st_size, "mtime": stat.st_mtime})
        except Exception:
            continue
    return jsonify({"incoming": files})


if __name__ == "__main__":
    # Run dev server
    host = os.getenv("WEBHOOK_HOST", "127.0.0.1")
    port = int(os.getenv("WEBHOOK_PORT", "5000"))
    print(f"Starting webhook_receiver on {host}:{port} (WEBHOOK_SECRET set? {'yes' if WEBHOOK_SECRET else 'no'})")
    app.run(host=host, port=port)