# -*- coding: utf-8 -*-
"""describe_layer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ric0LVcuLkYbUAIaFxT6e0BCNAE8WRjZ
"""

"""
describe_layer.py

Turns DataRepository + query_layer outputs into human-readable text.
No direct CSV access here, only structured data from query_layer.
"""
import re
import pandas as pd
from typing import Optional
from textwrap import indent
from .utils.io import load_csv_safe
from datetime import datetime
from .data_layer import DataRepository
from .query_layer import (
    get_workers_by_year,
    get_top_occupations,
    get_households_by_governorate,
    get_latest_density,
    get_housing_units_summary,
    get_students_summary,
    get_teachers_summary,
    get_higher_education_summary,
)

import re
import pandas as pd

def short_pct(v, total):
    try:
        return f"{100*v/total:.1f}%"
    except:
        return "0%"

def summarize_df_by(df, groupby_cols, value_col=None, top_n=5):
    if value_col:
        agg = df.groupby(groupby_cols)[value_col].sum().reset_index()
    else:
        agg = df.groupby(groupby_cols).size().reset_index(name="count")
    agg = agg.sort_values(by=agg.columns[-1], ascending=False).head(top_n)
    return agg


def extract_year_from_series(s: pd.Series) -> int | None:
    """
    Robustly extract an integer year from a Series that may contain:
      - integers (2023)
      - numeric strings ("2023")
      - year-month ("2023-12")
      - full dates ("2023-12-01" or other parseable formats)
    Returns max year found or None.
    """
    if s is None or s.empty:
        return None

    # 1. Try numeric conversion (fast path)
    try:
        nums = pd.to_numeric(s, errors="coerce")
        if nums.notna().any():
            years = nums.dropna().astype(int)
            if len(years) > 0:
                return int(years.max())
    except Exception:
        pass

    # 2. Parse strings like "YYYY", "YYYY-MM", "YYYY-MM-DD"
    def parse_year_from_string(val):
        if not isinstance(val, str):
            return None
        v = val.strip()
        m = re.match(r"^(\d{4})(?:[-/].*)?$", v)
        if m:
            return int(m.group(1))
        return None

    parsed = []
    for v in pd.Series(s).dropna().unique():
        try:
            y = parse_year_from_string(v)
            if y:
                parsed.append(y)
        except Exception:
            continue
    if parsed:
        return int(max(parsed))

    # 3. Fallback: use pandas to_datetime and extract year
    try:
        dt = pd.to_datetime(s, errors="coerce", utc=True)
        if dt.notna().any():
            return int(dt.dt.year.max())
    except Exception:
        pass

    return None

def describe_labour_market(repo: DataRepository, year: Optional[int]) -> str:
    workers = get_workers_by_year(repo, year)
    top_occ = get_top_occupations(repo, year, top_n=3)

    if workers.empty and top_occ.empty:
        if year is None:
            return "I couldn't find any labour market data in the current dataset."
        return f"I couldn't find labour market data for {year} in the current dataset."

    lines = []
    if year is not None:
        lines.append(f"Labour market overview for {year} in Bahrain:\n")
    else:
        lines.append("Labour market overview for Bahrain:\n")

    if not workers.empty:
        total = int(workers["total_workers"].sum())
        lines.append(f"- Total recorded workers: {total:,}")

        top_nat = workers.iloc[0]
        lines.append(
            f"- Largest nationality group: {top_nat['nationality']} "
            f"with {int(top_nat['total_workers']):,} workers"
        )

    if not top_occ.empty:
        lines.append("\nTop 3 occupations by number of workers:")
        for _, row in top_occ.iterrows():
            lines.append(
                f"- {row['main_occupation']}: {int(row.iloc[1]):,} workers"
            )

    return "\n".join(lines)


def describe_governorates(repo: DataRepository) -> str:
    households = get_households_by_governorate(repo)
    density = get_latest_density(repo)

    if households.empty and density.empty:
        return "I couldn't find households or population density data in the current dataset."

    lines = []
    lines.append("Households and population density by governorate:\n")

    if not households.empty:
        lines.append("Households by governorate:")
        # Show top governorates
        top = households.head(10)
        for _, row in top.iterrows():
            gov = row.get("governorate", "Unknown governorate")
            val = row.iloc[-1]
            nat = row.get("nationality")
            if nat:
                lines.append(f"- {gov} ({nat}): {int(val):,} households")
            else:
                lines.append(f"- {gov}: {int(val):,} households")

    if not density.empty:
        latest_year = extract_year_from_series(density["year"]) if "year" in density.columns else None
        if latest_year:
            lines.append(f"\nLatest population density data (year {latest_year}):")
        else:
            lines.append("\nLatest population density data:")

        for _, row in density.iterrows():
            gov = row.get("governorate", "Unknown governorate")
            pop = row.get("population")
            dens = row.get("density")
            if pop is not None and dens is not None:
                lines.append(f"- {gov}: population {int(pop):,}, density {dens} people/km²")
            elif pop is not None:
                lines.append(f"- {gov}: population {int(pop):,}")
            else:
                lines.append(f"- {gov}: density data available")

    return "\n".join(lines)


def describe_housing_units(repo: DataRepository) -> str:
    df = get_housing_units_summary(repo)
    if df.empty:
        return "I couldn't find housing units data in the current dataset."

    lines = ["Housing units by governorate and type:\n"]
    top = df.head(15)
    for _, row in top.iterrows():
        gov = row.get("governorate", "Unknown governorate")
        htype = row.get("housing_type", "All types")
        units = row.iloc[-1]
        lines.append(f"- {gov} – {htype}: {int(units):,} units")

    return "\n".join(lines)



def describe_students(data_path="data/bahrain_master"):
    # students.csv may be duplicate of higher_education but keep separated
    # safe extraction of repository root path for load_csv_safe
    repo_root = getattr(data_path, "data_dir", None) or getattr(data_path, "data_root", None) or getattr(data_path, "root_path", None) or getattr(data_path, "root", None) or getattr(data_path, "path", None) or str(data_path)
    df, err = load_csv_safe(repo_root, "students.csv")

    if err:
        return "No students CSV found. Expected file: students.csv in data/bahrain_master."
    df.columns = [c.strip() for c in df.columns]
    out = []
    out.append(f"Students dataset — {len(df)} rows, columns: {', '.join(df.columns)}")
    # totals if column exists
    if 'students' in (c.lower() for c in df.columns):
        total = int(df['students'].sum())
        out.append(f"Total students: {total}")
    # groupings examples
    if any('governor' in c.lower() for c in df.columns):
        gov = [c for c in df.columns if 'governor' in c.lower()][0]
        top = df.groupby(gov).agg({'students':'sum'})['students'].sort_values(ascending=False).head(5)
        out.append("Top governorates by students: " + ", ".join([f"{i} ({int(v)})" for i,v in top.items()]))
    return "\n".join(out)


def describe_teachers(repo: DataRepository) -> str:
    df = get_teachers_summary(repo)
    if df.empty:
        return "I couldn't find teachers data in the current dataset."

    lines = ["Teachers overview by school type and level:\n"]
    top = df.head(15)
    value_col = "teachers"
    for _, row in top.iterrows():
        desc_parts = []
        for c in ["school_type", "sector"]:
            if c in row and isinstance(row[c], str):
                desc_parts.append(row[c])
        level = row.get("level", "All levels")
        count = int(row[value_col])
        if desc_parts:
            lines.append(f"- {' / '.join(desc_parts)} – {level}: {count:,} teachers")
        else:
            lines.append(f"- {level}: {count:,} teachers")

    return "\n".join(lines)


def describe_higher_education(data_path="data/bahrain_master"):
    df, err = load_csv_safe(data_path, "higher_education.csv")
    if err:
        return ("No higher education CSV found. Expected file: higher_education.csv. "
                "Files present: check data/bahrain_master/ directory.")
    # basic cleaning
    # try to detect common columns: 'governorate','gender','year','students'
    cols = [c.lower() for c in df.columns]
    # standardize
    df.columns = [c.strip() for c in df.columns]
    total_students = None
    if 'students' in (c.lower() for c in df.columns):
        total_students = int(df['students'].sum())
    elif 'count' in (c.lower() for c in df.columns):
        total_students = int(df['count'].sum())
    # compute distributions if possible
    out = []
    out.append(f"Higher education — quick overview (rows: {len(df)}).")
    if total_students:
        out.append(f"Total students (sum of 'students'/'count'): {total_students}")
    # by governorate
    by_gov = None
    if any('governor' in c.lower() for c in df.columns):
        gov_col = [c for c in df.columns if 'governor' in c.lower()][0]
        by_gov = df.groupby(gov_col).agg({'students':'sum'})['students'] if 'students' in df.columns else df.groupby(gov_col).size()
        by_gov = by_gov.sort_values(ascending=False)
        out.append("Top governorates by students: " + ", ".join([f"{i} ({int(v)})" for i,v in by_gov.head(5).items()]))
    # gender distribution
    if any('gender' in c.lower() for c in df.columns):
        gcol = [c for c in df.columns if 'gender' in c.lower()][0]
        if 'students' in df.columns:
            gdist = df.groupby(gcol)['students'].sum()
        else:
            gdist = df.groupby(gcol).size()
        tot = gdist.sum()
        out.append("Gender split: " + ", ".join([f"{g}: {int(v)} ({short_pct(v, tot)})" for g,v in gdist.items()]))
    # timeframe if present
    if any('year' in c.lower() for c in df.columns):
        ycol = [c for c in df.columns if 'year' in c.lower()][0]
        years = sorted(df[ycol].dropna().unique().tolist())
        if years:
            out.append(f"Years available: {years[0]} to {years[-1]}")
    # return summary string
    return "\n".join(out)
